{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Preprocess import * \n",
    "from FeatureExtraction import *\n",
    "from plotting import *\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    7561\n",
      "0    7439\n",
      "Name: label, dtype: int64\n",
      "(15000, 2)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/WELFake_Dataset.csv')\n",
    "\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df = df.sample(n=5000, random_state=42)\n",
    "\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "X=df.drop(['label'],axis=1)\n",
    "y=df['label']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/news_articles.csv')\n",
    "\n",
    "# df.dropna(inplace=True)\n",
    "# df.drop(df[df['language'] != 'english'].index,inplace=True)\n",
    "# df=df.drop(['published','main_img_url','type','language','title_without_stopwords','text_without_stopwords'],axis=1)\n",
    "\n",
    "\n",
    "# print(df['label'].value_counts())\n",
    "\n",
    "# X=df.drop(['label'],axis=1)\n",
    "# y=df['label']\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54359</th>\n",
       "      <td>Live at Truthdig: Robert Scheer and Thomas Fra...</td>\n",
       "      <td>Live at Truthdig: Robert Scheer and Thomas Fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>The Mirage of a Return to Manufacturing Greatn...</td>\n",
       "      <td>Half a century ago, harvesting California’s 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28912</th>\n",
       "      <td>British PM expected to offer to fill post-Brex...</td>\n",
       "      <td>(Reuters) - The British government has told Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65965</th>\n",
       "      <td>Checkmating Obama</td>\n",
       "      <td>Originally published by the Jerusalem Post . \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>Thirty-eight injured in police charges in Cata...</td>\n",
       "      <td>MADRID (Reuters) - Emergency services have att...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "54359  Live at Truthdig: Robert Scheer and Thomas Fra...   \n",
       "6993   The Mirage of a Return to Manufacturing Greatn...   \n",
       "28912  British PM expected to offer to fill post-Brex...   \n",
       "65965                                  Checkmating Obama   \n",
       "2307   Thirty-eight injured in police charges in Cata...   \n",
       "\n",
       "                                                    text  \n",
       "54359  Live at Truthdig: Robert Scheer and Thomas Fra...  \n",
       "6993   Half a century ago, harvesting California’s 2....  \n",
       "28912  (Reuters) - The British government has told Ge...  \n",
       "65965  Originally published by the Jerusalem Post . \\...  \n",
       "2307   MADRID (Reuters) - Emergency services have att...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_counts = y.value_counts()\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.axis('equal')\n",
    "plt.title('Label Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54359    live truthdig robert scheer thomas frank talk ...\n",
      "6993     half century ago harvesting california million...\n",
      "28912    reuters british government told german chancel...\n",
      "Name: preprocessed_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X['preprocessed_text'] = preprocess_text(X['text'])\n",
    "print(X['preprocessed_text'].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)-gram\n",
      "LogisticRegression: [0.918, 0.909323116219668, 0.9319371727748691, 0.92049127343245]\n",
      "MultinomialNB: [0.839, 0.8767123287671232, 0.7958115183246073, 0.8343053173241851]\n",
      "RandomForestClassifier: [0.8993333333333333, 0.9027595269382391, 0.8992146596858639, 0.900983606557377]\n",
      "SVC: [0.937, 0.9344581440622972, 0.9424083769633508, 0.93841642228739]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m classifier_name \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m     28\u001b[0m classifier_metrics \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 30\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train_tfidf, y_train)\n\u001b[0;32m     31\u001b[0m y_pred \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test_tfidf)\n\u001b[0;32m     33\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    463\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    465\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    466\u001b[0m ]\n\u001b[0;32m    468\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    475\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    476\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    477\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    478\u001b[0m )(\n\u001b[0;32m    479\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    480\u001b[0m         t,\n\u001b[0;32m    481\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    482\u001b[0m         X,\n\u001b[0;32m    483\u001b[0m         y,\n\u001b[0;32m    484\u001b[0m         sample_weight,\n\u001b[0;32m    485\u001b[0m         i,\n\u001b[0;32m    486\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    487\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    488\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    489\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['preprocessed_text'], y, test_size=0.2, random_state=42)\n",
    "\n",
    "ngram_ranges = [(1, 1), (2, 2), (3, 3)]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "for ngram_range in tqdm(ngram_ranges):\n",
    "    metrics_dict = {}\n",
    "    vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    for classifier in tqdm(classifiers):\n",
    "        classifier_name = classifier.__class__.__name__\n",
    "        classifier_metrics = []\n",
    "\n",
    "        classifier.fit(X_train_tfidf, y_train)\n",
    "        y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        classifier_metrics.extend([accuracy, precision, recall, f1])\n",
    "        metrics_dict[classifier_name] = classifier_metrics\n",
    "\n",
    "    print(f\"{ngram_range}-gram\")\n",
    "    for classifier_name, classifier_metrics in metrics_dict.items():\n",
    "        print(f\"{classifier_name}: {classifier_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_graph([\"LR\",\"NB\",\"RF\",\"SVM\"],[0.912,0.854,0.891,0.916])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m X_train, X_test \u001b[39m=\u001b[39m X_tfidf[train_index], X_tfidf[test_index]\n\u001b[0;32m     37\u001b[0m y_train, y_test \u001b[39m=\u001b[39m y[train_index], y[test_index]\n\u001b[1;32m---> 39\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     40\u001b[0m y_pred \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     41\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    463\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    465\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    466\u001b[0m ]\n\u001b[0;32m    468\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    475\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    476\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    477\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    478\u001b[0m )(\n\u001b[0;32m    479\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    480\u001b[0m         t,\n\u001b[0;32m    481\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    482\u001b[0m         X,\n\u001b[0;32m    483\u001b[0m         y,\n\u001b[0;32m    484\u001b[0m         sample_weight,\n\u001b[0;32m    485\u001b[0m         i,\n\u001b[0;32m    486\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    487\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    488\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    489\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = X['preprocessed_text']\n",
    "y = np.array(y)\n",
    "\n",
    "ngram_ranges = [(1, 1), (2, 2), (3, 3)]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    MultinomialNB(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "metrics_dict = {}\n",
    "\n",
    "for classifier in tqdm(classifiers):\n",
    "    classifier_name = classifier.__class__.__name__\n",
    "    classifier_metrics = []\n",
    "\n",
    "    for ngram_range in tqdm(ngram_ranges):\n",
    "        vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n",
    "        X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "        accuracies = []\n",
    "        for train_index, test_index in kf.split(X_tfidf):\n",
    "            X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        classifier_metrics.append(mean_accuracy)\n",
    "\n",
    "    metrics_dict[classifier_name] = classifier_metrics\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    print(f\"{ngram_range}-gram\")\n",
    "    for classifier_name, classifier_metrics in metrics_dict.items():\n",
    "        print(f\"{classifier_name}: {classifier_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram range (1, 1):\n",
      "LogisticRegression: [0.8653333333333333, 0.8697368421052631, 0.8651832460732984, 0.8674540682414699]\n",
      "RandomForestClassifier: [0.8753333333333333, 0.8651898734177215, 0.8946335078534031, 0.8796653796653797]\n",
      "SVC: [0.8963333333333333, 0.8964169381107492, 0.900523560209424, 0.8984655566438131]\n",
      "n-gram range (2, 2):\n",
      "LogisticRegression: [0.8653333333333333, 0.8697368421052631, 0.8651832460732984, 0.8674540682414699]\n",
      "RandomForestClassifier: [0.8726666666666667, 0.8687258687258688, 0.8835078534031413, 0.8760545100584036]\n",
      "SVC: [0.8963333333333333, 0.8964169381107492, 0.900523560209424, 0.8984655566438131]\n",
      "n-gram range (3, 3):\n",
      "LogisticRegression: [0.8653333333333333, 0.8697368421052631, 0.8651832460732984, 0.8674540682414699]\n",
      "RandomForestClassifier: [0.873, 0.8683365446371226, 0.8848167539267016, 0.8764991896272286]\n",
      "SVC: [0.8963333333333333, 0.8964169381107492, 0.900523560209424, 0.8984655566438131]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "sentences = [text.split() for text in X['preprocessed_text']]\n",
    "word2vec_model = Word2Vec(sentences, min_count=1, vector_size=100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ngram_ranges = [(1, 1), (2, 2), (3, 3)]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    SVC()\n",
    "]\n",
    "\n",
    "metrics_dict = {}\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    ngram_metrics = {}\n",
    "    \n",
    "    #get vectors for each word in the sentence and average them using word2vec\n",
    "    X_train_word_vectors = np.array([np.mean([word2vec_model.wv[w] for w in words if w in word2vec_model.wv] or [np.zeros(100)], axis=0) for words in X_train])\n",
    "    X_test_word_vectors = np.array([np.mean([word2vec_model.wv[w] for w in words if w in word2vec_model.wv] or [np.zeros(100)], axis=0) for words in X_test])\n",
    "    \n",
    "    X_train_normalized = preprocessing.normalize(X_train_word_vectors, norm='l2')\n",
    "    X_test_normalized = preprocessing.normalize(X_test_word_vectors, norm='l2')\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        classifier_name = classifier.__class__.__name__\n",
    "        classifier_metrics = []\n",
    "\n",
    "        classifier.fit(X_train_normalized, y_train)\n",
    "        y_pred = classifier.predict(X_test_normalized)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        classifier_metrics.extend([accuracy, precision, recall, f1])\n",
    "        ngram_metrics[classifier_name] = classifier_metrics\n",
    "\n",
    "    metrics_dict[ngram_range] = ngram_metrics\n",
    "\n",
    "for ngram_range, ngram_metrics in metrics_dict.items():\n",
    "    print(f\"n-gram range {ngram_range}:\")\n",
    "    for classifier_name, classifier_metrics in ngram_metrics.items():\n",
    "        print(f\"{classifier_name}: {classifier_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 40)            200000    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, 40)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               56400     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(1500, 20)\n",
      "(1500,)\n",
      "Epoch 1/10\n",
      "19/19 [==============================] - 3s 46ms/step - loss: 0.6888 - accuracy: 0.5050 - val_loss: 0.6788 - val_accuracy: 0.6667\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.5849 - accuracy: 0.7983 - val_loss: 0.5441 - val_accuracy: 0.7067\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.3328 - accuracy: 0.8783 - val_loss: 0.5157 - val_accuracy: 0.7367\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.1539 - accuracy: 0.9492 - val_loss: 0.6848 - val_accuracy: 0.7033\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 0s 20ms/step - loss: 0.0559 - accuracy: 0.9875 - val_loss: 1.1784 - val_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0372 - accuracy: 0.9908 - val_loss: 1.2469 - val_accuracy: 0.6700\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 1.0150 - val_accuracy: 0.7000\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0223 - accuracy: 0.9958 - val_loss: 1.3132 - val_accuracy: 0.6933\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 0s 19ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 1.4445 - val_accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 0s 18ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 1.3436 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b97685720>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "voc_size=5000\n",
    "onehot_repr=[one_hot(words,voc_size)for words in X['preprocessed_text']]\n",
    "\n",
    "sentence_len=20\n",
    "embedded_doc = pad_sequences(onehot_repr,padding='pre',maxlen=sentence_len)\n",
    "\n",
    "embedding_vec_feature=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vec_feature,input_length=sentence_len))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_f=np.array(embedded_doc)\n",
    "y_f=np.array(y)\n",
    "print(X_f.shape)\n",
    "print(y_f.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_f, y_f, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
